---
title: "Assignment 2"
author: "Molly F-F & Brittany O"
date: "2024-09-28"
output: html_document
---

```{r}
library(tidyverse)
library(gtrendsR)
library(censusapi)
library(dplyr)
```

#Pulling from APIs
Our first data source is the Google Trends API. Suppose we are interested in the search trends
for crime and loans in Illinois in the year 2020. We could find this using the following code:
```{r}
res <- gtrends(c("crime", "loans"),
               geo = "US-IL",
               time = "2020-01-01 2020-12-31",
               low_search_volume = TRUE)
plot(res)
```

Answer the following questions for the keywords “crime” and “loans”.

• Find the mean, median and variance of the search hits for the keywords.

CRIME:                     LOANS
Mean: 51.01887             Mean: 62.24528
Median: 51                 Median: 60
Var.: 67.36502             Var: 98.72714
```{r}
head(res$interest_over_time)
res_time <- as_tibble(res$interest_over_time)
glimpse(res_time)

res_time_w <- spread(res_time, key = keyword, value = hits)
head(res_time_w)

mean(res_time_w$crime) #51.01887
median(res_time_w$crime) #51
var(res_time_w$crime) #67.36502


mean(res_time_w$loans) #62.24528
median(res_time_w$loans) #60
var(res_time_w$loans) #98.72714


#Molly's answers: 55.28302, 55, 84.28374; 67.13208, 65, 102.2707
```

• Which cities (locations) have the highest search frequency for loans? Note that there
might be multiple rows for each city if there were hits for both “crime” and “loans” in
that city. It might be easier to answer this question if we had the search hits info for
both search terms in two separate variables. That is, each row would represent a unique
city.

- Long Lake, Peotone, Rosemont, East Saint Louis, and Ford Heights are the top 5 locations for 'loans' search hits. 
```{r}
head(res$interest_by_city)
res_city <- as_tibble(res$interest_by_city)
glimpse(res_city)

res_city_w <- spread(res_city, key = keyword, value = hits)
head(res_city_w)
loansbycity <-  res_city_w %>%
  group_by(location) %>%
  summarize(loans = sum(loans)) %>%
  arrange(desc(loans))

na.omit(loansbycity)

#Molly's answers: Long Lake, oak Lawn, Rosemont, Coal City, Ford Heights
```

• Is there a relationship between the search intensities between the two keywords we used?
```{r}
res_both_w <- res_city_w %>% 
  drop_na() 
res_both_w
```

###Repeat the above for keywords related to covid. Make sure you use multiple keywords like we did above. Try several different combinations and think carefully about words that might make sense within this context.
```{r}
covid.search1 <- gtrends(c("covid", "vaccine"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search1)
```
```{r}
covid.search2 <- gtrends(c("covid", "test"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search2)
```
```{r}
covid.search3 <- gtrends(c("covid", "lockdown"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search3)
```
```{r}
covid.search4 <- gtrends(c("covid", "mask"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search4)
```
```{r}
covid.search5 <- gtrends(c("covid", "distancing"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search5)
```
```{r}
covid.search6 <- gtrends(c("covid", "China"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search6)
```
```{r}
covid.search7 <- gtrends(c("covid", "trump"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search7)
```
```{r}
covid.search8 <- gtrends(c("covid", "biden"),
geo = "US-IL",
time = "2020-01-01 2020-12-31",
low_search_volume = TRUE)
plot(covid.search8)
```
```{r}
rm(covid.search1,covid.search2, covid.search3, covid.search5, covid.search6, covid.search7, covid.search8)

head(covid.search4$interest_over_time)
covid_time <- as_tibble(covid.search4$interest_over_time)
glimpse(covid_time)

covid_time_w <- spread(covid_time, key = keyword, value = hits)
head(covid_time_w)
glimpse(covid_time_w)

covid_time_w$covid <- as.numeric(covid_time_w$covid)
covid_time_w$mask <- as.numeric(covid_time_w$mask)
glimpse(covid_time_w)

mean(covid_time_w$covid, na.rm = TRUE) #47.58824
median(covid_time_w$covid, na.rm = TRUE) #52 
var(covid_time_w$covid, na.rm = TRUE) #615.7271

mean(covid_time_w$mask) #10.43396
median(covid_time_w$mask) #9
var(covid_time_w$mask) #40.51959
```

```{r}
head(covid.search4$interest_by_city)
covid_city <- as_tibble(covid.search4$interest_by_city)
glimpse(covid_city)

covid_city_w <- spread(covid_city, key = keyword, value = hits)
head(covid_city_w)
maskbycity <-  covid_city_w %>%
  group_by(location) %>%
  summarize(mask = sum(mask)) %>%
  arrange(desc(mask))

na.omit(maskbycity)
#Top 5 cities for 'mask' search results are Minier, Oakdale, Bushnell, Keyesport, Forsyth
```

#Google Trends + ACS

Once you have a Census access key, save it as a text file, then read this key in the cs_key object. We
will use this object in all following API queries. 

```{r}
cs_key <- read_file("~/Downloads/census-key.txt")
```

In the following, we request basic socio-demographic information (population, median age,
median household income, income per capita) for cities and villages in the state of Illinois.
```{r}
acs_il <- getCensus(name = "acs/acs5",
                    vintage = 2020,
                    vars = c("NAME",
                             "B01001_001E",
                             "B06002_001E",
                             "B19013_001E",
                             "B19301_001E"),
                    region = "place:*",
                    regionin = "state:17",
                    key = cs_key)
head(acs_il)
```

Convert values that represent missings to NAs.
```{r}
acs_il[acs_il == -666666666] <- NA
```

Now, it might be useful to rename the socio-demographic variables (B01001_001E etc.) in our
data set and assign more meaningful names.
```{r}
acs_il <-
  acs_il %>%
  rename(pop = B01001_001E,
         age = B06002_001E,
         hh_income = B19013_001E,
         income = B19301_001E)
```

Answer the following questions with the “crime” and “loans” Google trends data and the ACS
data.

• First, check how many cities don’t appear in both data sets, i.e. cannot be matched.
Then, create a new data set by joining the Google Trends and the ACS data. Keep only
cities that appear in both data sets.
```{r}
head(res_city)
head(acs_il)

#create location variable that removes the type of location and state name from the label
acs_il$location <- gsub("\\s\\S+,.+$", "", acs_il$NAME)

anti_join(res_city_w, acs_il, by="location")
anti_join(acs_il, res_city_w, by="location")
```

There are 9 cities in the Google Trends data that can't be matched to the ACS dataset, while there are 1120 locations in the ACS dataset for which there are no Google Trends data.

``` {r}
GT_ACS1 <- res_city_w %>% inner_join(acs_il, by="location")
head(GT_ACS1)
```

• Compute the mean of the search popularity for both keywords for cities that have an
above average median household income and for those that have an below average median
household income. When building your pipe, start with creating the grouping variable
and then proceed with the remaining tasks. What conclusions might you draw from
this?

```{r}
#calculate average median income
median_income <- median(GT_ACS1$hh_income, na.rm=T)

#note that the median income is not included here
GT_ACS1$income2[GT_ACS1$hh_income < median_income] <- "Below avg median HH income"
GT_ACS1$income2[GT_ACS1$hh_income > median_income] <- "Above avg median HH income"
table(GT_ACS1$income2)

GT_ACS1 %>% group_by(income2) %>% summarise(crime_hits = mean(crime, na.rm=T),
                                            loans_hits = mean(loans, na.rm=T))
```

TKTKTK add things here

• Is there a relationship between the median household income and the search popularity of
the Google trends terms? Describe the relationship and use a scatterplot with qplot().
```{r}
qplot(hh_income, crime, data=GT_ACS1)
qplot(hh_income, loans, data=GT_ACS1)
```

###Repeat the above steps using the covid data and the ACS data.
```{r}

#merge data
GT_ACS2 <- covid_city_w %>% inner_join(acs_il, by="location")
head(GT_ACS1)

#calculate average median income
median_income <- median(GT_ACS2$hh_income, na.rm=T)


#note that the median income is not included here
GT_ACS2$income2[GT_ACS2$hh_income < median_income] <- "Below avg median HH income"
GT_ACS2$income2[GT_ACS2$hh_income > median_income] <- "Above avg median HH income"
table(GT_ACS1$income2)

GT_ACS2 %>% group_by(income2) %>% summarise(crime_hits = mean(crime, na.rm=T),
                                            loans_hits = mean(loans, na.rm=T))

qplot(hh_income, crime, data=GT_ACS2)
qplot(hh_income, loans, data=GT_ACS2)

```